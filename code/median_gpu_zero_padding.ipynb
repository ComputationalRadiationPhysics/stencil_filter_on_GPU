{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load needed modules\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from math import ceil \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out gpu information\n",
    "gpu = numba.cuda.get_current_device()\n",
    "print(\"name = %s\" % gpu.name)\n",
    "print(\"maxThreadsPerBlock = %s\" % str(gpu.MAX_THREADS_PER_BLOCK))\n",
    "print(\"maxBlockDimX = %s\" % str(gpu.MAX_BLOCK_DIM_X))\n",
    "print(\"maxBlockDimY = %s\" % str(gpu.MAX_BLOCK_DIM_Y))\n",
    "print(\"maxBlockDimZ = %s\" % str(gpu.MAX_BLOCK_DIM_Z))\n",
    "print(\"maxGridDimX = %s\" % str(gpu.MAX_GRID_DIM_X))\n",
    "print(\"maxGridDimY = %s\" % str(gpu.MAX_GRID_DIM_Y))\n",
    "print(\"maxGridDimZ = %s\" % str(gpu.MAX_GRID_DIM_Z))\n",
    "print(\"maxSharedMemoryPerBlock = %s\" % str(gpu.MAX_SHARED_MEMORY_PER_BLOCK))\n",
    "print(\"asyncEngineCount = %s\" % str(gpu.ASYNC_ENGINE_COUNT))\n",
    "print(\"canMapHostMemory = %s\" % str(gpu.CAN_MAP_HOST_MEMORY))\n",
    "print(\"multiProcessorCount = %s\" % str(gpu.MULTIPROCESSOR_COUNT))\n",
    "print(\"warpSize = %s\" % str(gpu.WARP_SIZE))\n",
    "print(\"unifiedAddressing = %s\" % str(gpu.UNIFIED_ADDRESSING))\n",
    "print(\"pciBusID = %s\" % str(gpu.PCI_BUS_ID))\n",
    "print(\"pciDeviceID = %s\" % str(gpu.PCI_DEVICE_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================= median ================================== #\n",
    "\n",
    "@cuda.jit\n",
    "def gpu_median_zero_padding(input_data, output_data, stencil_z, stencil_y, stencil_x, Nz, Ny, Nx):\n",
    "    \n",
    "    # ==== full kernel size ==== #\n",
    "    dx = 2*stencil_x+1\n",
    "    dy = 2*stencil_y+1\n",
    "    dz = 2*stencil_z+1\n",
    "\n",
    "    row_init = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "    col_init = cuda.threadIdx.y + cuda.blockIdx.y * cuda.blockDim.y\n",
    "    depth_init = cuda.threadIdx.z + cuda.blockIdx.z * cuda.blockDim.z\n",
    "    \n",
    "    # grid stride:\n",
    "    for depth_global in range(depth_init, Nz, cuda.blockDim.z * cuda.gridDim.z):\n",
    "        z_min = max(depth_global - stencil_z, 0)\n",
    "        z_max = min(depth_global + stencil_z + 1, Nz)\n",
    "        for col_global in range(col_init, Ny, cuda.blockDim.y * cuda.gridDim.y):\n",
    "            y_min = max(col_global - stencil_y, 0)\n",
    "            y_max = min(col_global + stencil_y + 1, Ny)\n",
    "            for row_global in range(row_init, Nx, cuda.blockDim.x * cuda.gridDim.x):\n",
    "                \n",
    "                x_min = max(row_global - stencil_x, 0)\n",
    "                x_max = min(row_global + stencil_x + 1, Nx)\n",
    "                \n",
    "                # define local array in cuda: \n",
    "                # https://stackoverflow.com/questions/48642481/what-is-the-correct-usage-of-cuda-local-array-in-numba\n",
    "                # BE AWARE!: Array has to be big enough to store the data of the whole kernal\n",
    "                sort_array = cuda.local.array(10 * 8 * 10, numba.float32) \n",
    "                \n",
    "                \n",
    "                \n",
    "                # load in local memory to sort\n",
    "                m = 0\n",
    "                for i in range(z_min,z_max):\n",
    "                    for j in range(y_min,y_max):\n",
    "                        for k in range(x_min,x_max):\n",
    "                            sort_array[m] = input_data[i,j,k]\n",
    "                            m += 1\n",
    "                            \n",
    "                # full size of the kernel\n",
    "                n = dx*dy*dz\n",
    "                \n",
    "                # fill up the rest of the array with zeros\n",
    "                for i in range(m,n):\n",
    "                    sort_array[n] = 0\n",
    "                \n",
    "                # selection sort:\n",
    "                # https://www.cnblogs.com/BobHuang/p/11263183.html <== chinese website\n",
    "                for i in range(n - 1):\n",
    "                    min_index = i;                  \n",
    "                    for j in range(i+1, n):\n",
    "                        if (sort_array[j] < sort_array[min_index]):\n",
    "                            min_index = j; \n",
    "                \n",
    "                    #swap(sort_array[i], sort_array[minIndex]);\n",
    "                    tmp = sort_array[i]\n",
    "                    sort_array[i] = sort_array[min_index]\n",
    "                    sort_array[min_index] = tmp\n",
    "                    \n",
    "                half = int(n / 2)\n",
    "                if (n % 2) == 1:\n",
    "                    median = sort_array[half]\n",
    "                else:\n",
    "                    median = (sort_array[half-1] + sort_array[half]) / 2.0\n",
    "             \n",
    "                output_data[depth_global, col_global, row_global] = median\n",
    "                \n",
    "\n",
    "        \n",
    "def lauch_kernel(input_data, output_data, stencil_):\n",
    "    # TODO: set blocksize, gridsize and lauch kernel\n",
    "    # define threads and blocks\n",
    "    threads = (16, 8, 4)\n",
    "    blocks = (8, 8, 8)\n",
    "    print(\"==================\")\n",
    "    print(\"threads: \" + str(threads))\n",
    "    print(\"blocks: \" + str(blocks))\n",
    "    print(\"==================\")\n",
    "    \n",
    "    Nz, Ny, Nx = np.shape(input_data) # why here z, y, x ?\n",
    "    stencil_z, stencil_y, stencil_x = stencil_[0], stencil_[1], stencil_[2]\n",
    "  \n",
    "    # call CUDA kernel\n",
    "    gpu_median_zero_padding[threads, blocks](input_data, output_data,stencil_z, stencil_y, stencil_x, Nz, Ny, Nx)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate dummy data for test\n",
    "\n",
    "Nz, Ny, Nx = 128, 512, 128\n",
    "\n",
    "real_data = (np.ones((Nz, Ny, Nx)) * np.sin(np.linspace(0, 20, Ny)[np.newaxis, :, np.newaxis])*0.5 \n",
    "             + np.random.normal(scale=1.0, size=(Nz, Ny, Nx)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visulize date: before filtering:\n",
    "\n",
    "plt.pcolormesh(real_data[Nz//2,:, :], vmin=-2, vmax=2, cmap=plt.cm.jet)\n",
    "\n",
    "cb = plt.colorbar()\n",
    "for i in cb.ax.get_yticklabels():\n",
    "    i.set_fontsize(14)\n",
    "    \n",
    "plt.xlabel(\"x-index\", fontsize=18)\n",
    "plt.xticks( fontsize=14)\n",
    "plt.ylabel(\"y-index\", fontsize=18)\n",
    "plt.yticks( fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the output result: same size of input data\n",
    "output_data_ = real_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stencil_t = np.array([1, 2, 1])\n",
    "\n",
    "start = time.time()\n",
    "lauch_kernel(real_data, output_data_, stencil_t)\n",
    "end = time.time()\n",
    "print(\"Elapsed (gpu naive with compilation) = %s\" % (end - start))\n",
    "\n",
    "start = time.time()\n",
    "lauch_kernel(real_data, output_data_, stencil_t)\n",
    "end = time.time()\n",
    "print(\"Elapsed (gpu naive without compilation) = %s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visulize date: after filtering:\n",
    "plt.pcolormesh(output_data_[Nz//2,:, :], vmin=-2, vmax=2, cmap=plt.cm.jet)\n",
    "\n",
    "cb = plt.colorbar()\n",
    "for i in cb.ax.get_yticklabels():\n",
    "    i.set_fontsize(14)\n",
    "    \n",
    "plt.xlabel(\"x-index\", fontsize=18)\n",
    "plt.xticks( fontsize=14)\n",
    "plt.ylabel(\"y-index\", fontsize=18)\n",
    "plt.yticks( fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k80_numba",
   "language": "python",
   "name": "k80_numba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
